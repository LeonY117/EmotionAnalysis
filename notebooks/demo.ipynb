{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNGnl0YMWtkVCIALpXlMlQ9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# NLP Project Demo - Multi-task learning for Text-based Emotion Detection across disparate label spaces\n","\n","### What's in this notebook\n","\n","\n","### How to run this notebook\n","This notebook is completely self-contained and runnable in a google colab environment\n"],"metadata":{"id":"f6s39IN0eOMu"}},{"cell_type":"markdown","source":["## Install & import"],"metadata":{"id":"P3MP0EFbe60T"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"jY3kwX7mdRTn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680447665614,"user_tz":-60,"elapsed":24801,"user":{"displayName":"Leon Yao","userId":"15846177251700038630"}},"outputId":"6f7a154c-8a08-48b9-aae9-f14ade4a0c41"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install transformers -q"]},{"cell_type":"code","source":["import torch \n","import torch.nn as nn\n","import transformers\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","from torch import ones_like, zeros_like\n","\n","import os\n","import math\n","import copy\n","import numpy as np \n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","from tqdm.notebook import tqdm\n","\n","from transformers import AutoModel, BertTokenizerFast\n","\n","DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(DEVICE)\n","\n","# set manual seed \n","np.random.seed(42)\n","torch.manual_seed(42)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YFrt3jNBe-Nc","executionInfo":{"status":"ok","timestamp":1680447869159,"user_tz":-60,"elapsed":290,"user":{"displayName":"Leon Yao","userId":"15846177251700038630"}},"outputId":"5dc4d3bb-57e7-4b9b-ddd7-93e22eab0bfb"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]},{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fbc300d0530>"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["!git clone https://github.com/LeonY117/EmotionAnalysis.git -q"],"metadata":{"id":"rAZnskdTf6pz","executionInfo":{"status":"ok","timestamp":1680447890858,"user_tz":-60,"elapsed":3813,"user":{"displayName":"Leon Yao","userId":"15846177251700038630"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# load the cleaned up dataset from github\n","CLEAN_DATA_DIR = \"/content/EmotionAnalysis/data/clean/\"\n","CHILDREN_filename = \"children_test.csv\"\n","EMOBANK_filename = \"emobank_test.csv\"\n","SEM_filename = \"SemEval2018_test.csv\"\n","\n","df_children = pd.read_csv(os.path.join(CLEAN_DATA_DIR, CHILDREN_filename))\n","df_emobank = pd.read_csv(os.path.join(CLEAN_DATA_DIR, EMOBANK_filename))\n","df_sem = pd.read_csv(os.path.join(CLEAN_DATA_DIR, SEM_filename))\n","\n","print(f'Fairy Tale: {len(df_children)}, EmoBank: {len(df_emobank)}, SemEval: {len(df_sem)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"48trpPWJf6D9","executionInfo":{"status":"ok","timestamp":1680448828214,"user_tz":-60,"elapsed":218,"user":{"displayName":"Leon Yao","userId":"15846177251700038630"}},"outputId":"c4a10a3b-f817-4ffc-f768-b0dce2fcf153"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Fairy Tale: 122, EmoBank: 982, SemEval: 3259\n"]}]},{"cell_type":"markdown","source":["### Define some global variables"],"metadata":{"id":"VTFWM16AkNav"}},{"cell_type":"code","source":["EKMAN_EMOTIONS = ['anger-disgust', 'fear', 'happy', 'sad', 'surprise']\n","SEM_EMOTIONS = ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']\n","VAD_EMOTIONS = ['V', 'A', 'D']\n","\n","# outputs heads (prediction heads)\n","NUM_CLASSES_EKMAN = len(EKMAN_EMOTIONS) # 5\n","NUM_CLASSES_SEM = len(SEM_EMOTIONS) # 11\n","NUM_CLASSES_VAD = len(VAD_EMOTIONS) # 3\n","\n","OUT_DIMS = {\n","    'ekman': NUM_CLASSES_EKMAN, 'vad': NUM_CLASSES_VAD, 'sem': NUM_CLASSES_SEM\n","}\n","\n","# label lengths (this is how many slots it takes to store the labels)\n","Y_DIM_EKMAN = 1\n","Y_DIM_VAD = NUM_CLASSES_VAD\n","Y_DIM_SEM = NUM_CLASSES_SEM\n","\n","Y_DIMS = {\n","    'ekman': Y_DIM_EKMAN, 'vad': Y_DIM_VAD, 'sem': Y_DIM_SEM\n","}"],"metadata":{"id":"49kQM7qBkPye","executionInfo":{"status":"ok","timestamp":1680449013857,"user_tz":-60,"elapsed":223,"user":{"displayName":"Leon Yao","userId":"15846177251700038630"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["## Model Definition"],"metadata":{"id":"tY_hwoyhj0Eq"}},{"cell_type":"markdown","source":["### Download tokenizer & Bert"],"metadata":{"id":"sYfwUYwrkWyB"}},{"cell_type":"code","source":["# Load the BERT tokenizer\n","pretrained_checkpoint = 'bert-base-uncased' \n","\n","tokenizer = BertTokenizerFast.from_pretrained(pretrained_checkpoint)\n","\n","# import BERT-base pretrained model\n","bert = AutoModel.from_pretrained(pretrained_checkpoint)"],"metadata":{"id":"OmakWfTpkaXe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Multihead \n","\n","This is the class which contains the shared base and the predictors"],"metadata":{"id":"7Jp4Wi-oj2TG"}},{"cell_type":"code","source":["class MultiheadNetwork(nn.Module):\n","  def __init__(self, h_size=256, dropout=0):\n","    super().__init__()\n","    \n","    self.shared_base = nn.Linear(768, h_size)\n","    self.ekman_predictor = nn.Linear(h_size, OUT_DIMS['ekman'])\n","    self.vad_predictor = nn.Linear(h_size, OUT_DIMS['vad'])\n","    self.sem_predictor = nn.Linear(h_size, OUT_DIMS['sem'])\n","\n","    self.dropout = nn.Dropout(p=dropout, inplace=False)\n","    self.relu = nn.ReLU()\n","    # self.softmax = nn.Softmax(dim=1)\n","    self.sigmoid = nn.Sigmoid()\n","    self.softmax = nn.LogSoftmax(dim=1)\n","\n","  def forward(self, X, task):  \n","    \n","    X = self.relu(self.shared_base(X))\n","    X = self.dropout(X)\n","\n","    ekman_filter = task[:, 0].unsqueeze(-1)\n","    y_ekman = ekman_filter * self.ekman_predictor(X)\n","    y_ekman = self.softmax(y_ekman)\n","\n","    vad_filter = task[:, 1].unsqueeze(-1)\n","    y_vad = vad_filter * self.vad_predictor(X)\n","    y_vad = self.relu(y_vad)\n","\n","    sem_filter = task[:, 2].unsqueeze(-1)\n","    y_sem = sem_filter * self.sem_predictor(X)\n","    y_sem = self.sigmoid(y_sem)\n","\n","    y = torch.concat((y_ekman, y_vad, y_sem), dim=1)\n","\n","    return y"],"metadata":{"id":"yyVKbTskgToZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Full model\n","\n","This includes the preprocessing steps"],"metadata":{"id":"502PceptkE_7"}},{"cell_type":"code","source":[],"metadata":{"id":"66vw91qykHAf"},"execution_count":null,"outputs":[]}]}