{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EmoBank"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in EmoBank and AffectiveText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmoBank:\n",
      "                    id  split     V     A     D  \\\n",
      "0  110CYL068_1036_1079  train  3.00  3.00  3.20   \n",
      "1  110CYL068_1079_1110   test  2.80  3.10  2.80   \n",
      "2  110CYL068_1127_1130  train  3.00  3.00  3.00   \n",
      "3  110CYL068_1137_1188  train  3.44  3.00  3.22   \n",
      "4  110CYL068_1189_1328  train  3.55  3.27  3.46   \n",
      "\n",
      "                                                text  \n",
      "0        Remember what she said in my last letter? \"  \n",
      "1                          If I wasn't working here.  \n",
      "2                                                ..\"  \n",
      "3  Goodwill helps people get off of public assist...  \n",
      "4  Sherry learned through our Future Works class ...  \n",
      "AffectiveText:\n",
      "   id                                   instance  anger  disgust  fear  joy  \\\n",
      "0   1     Mortar assault leaves at least 18 dead     22        2    60    0   \n",
      "1   2                     Goal delight for Sheva      0        0     0   93   \n",
      "2   3       Nigeria hostage feared dead is freed     18        0    52   66   \n",
      "3   4                      Bombers kill shoppers     66       39    94    0   \n",
      "4   5  Vegetables, not fruit, slow brain decline      0        0    25   26   \n",
      "\n",
      "   sadness  surprise  \n",
      "0       64         0  \n",
      "1        0        38  \n",
      "2       20        65  \n",
      "3       86         0  \n",
      "4        2        46  \n"
     ]
    }
   ],
   "source": [
    "# EmoBank\n",
    "eb = pd.read_csv('../data/raw/emobank.csv')\n",
    "print(\"EmoBank:\")\n",
    "print(eb.head())\n",
    "# drop duplicate text values\n",
    "eb = eb.drop_duplicates(subset=['text'], keep=False)\n",
    "# save to csv\n",
    "eb.to_csv('../data/clean/emobank.csv', index=False)\n",
    "\n",
    "# AffectiveText trial\n",
    "at = pd.read_xml('../data/raw/AffectiveText/AffectiveText.trial/affectivetext_trial.xml')\n",
    "columns = ['id', 'anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n",
    "at_em = pd.read_csv('../data/raw/AffectiveText/AffectiveText.trial/affectivetext_trial_emotions.csv'\\\n",
    "                    ,names=columns, sep=' ')\n",
    "# add emotion labels to at\n",
    "for emotion in columns[1:]:\n",
    "    at[emotion] = at_em[emotion]\n",
    "\n",
    "# AffectiveText test\n",
    "at_test = pd.read_xml('../data/raw/AffectiveText/AffectiveText.test/affectivetext_test.xml')\n",
    "at_test_em = pd.read_csv('../data/raw/AffectiveText/AffectiveText.test/affectivetext_test_emotions.csv'\\\n",
    "                    , names=columns, sep=' ')\n",
    "# add emotion labels to at_test\n",
    "for emotion in columns[1:]:\n",
    "    at_test[emotion] = at_test_em[emotion]\n",
    "    \n",
    "# combine at and at_test\n",
    "at = pd.concat([at, at_test], ignore_index=True)\n",
    "print(\"AffectiveText:\")\n",
    "print(at.head())\n",
    "# drop duplicate text values\n",
    "at = at.drop_duplicates(subset=['instance'], keep=False)\n",
    "# save to csv\n",
    "at.to_csv('../data/clean/AffectiveText.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in SemEval2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SemEval2018:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“Worry is a down payment on a problem you may ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whatever you decide to do make sure it makes y...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Max_Kellerman  it also helps that the majorit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accept the challenges so that you can literall...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>My roommate: it's okay that we can't spell bec...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text anger anticipation  \\\n",
       "1  “Worry is a down payment on a problem you may ...     0            1   \n",
       "2  Whatever you decide to do make sure it makes y...     0            0   \n",
       "3  @Max_Kellerman  it also helps that the majorit...     1            0   \n",
       "4  Accept the challenges so that you can literall...     0            0   \n",
       "5  My roommate: it's okay that we can't spell bec...     1            0   \n",
       "\n",
       "  disgust fear joy love optimism pessimism sadness surprise trust  \n",
       "1       0    0   0    0        1         0       0        0     1  \n",
       "2       0    0   1    1        1         0       0        0     0  \n",
       "3       1    0   1    0        1         0       0        0     0  \n",
       "4       0    0   1    0        1         0       0        0     0  \n",
       "5       1    0   0    0        0         0       0        0     0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SemEval2018\n",
    "se_train = pd.read_csv('../data/raw/SemEval2018/2018-E-c-En-train.txt', sep='\\t', names=['ID', 'text', 'anger', 'anticipation', 'disgust', 'fear', 'joy',\t'love',\t'optimism', 'pessimism', 'sadness',\t'surprise',\t'trust'])\n",
    "# drop the first row\n",
    "se_train = se_train.drop([0])\n",
    "# drop the ID column\n",
    "se_train = se_train.drop(['ID'], axis=1)\n",
    "\n",
    "se_train.to_csv('../data/clean/SemEval2018_train.csv', index=False)\n",
    "print(\"SemEval2018:\")\n",
    "se_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SemEval2018:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>@BadHombreNPS @SecretaryPerry If this didn't m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>Excited to watch #stateoforigin tonight! Come ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>Blah blah blah Kyrie, IT, etc. @CJC9BOSS leavi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>#ThingsIveLearned The wise #shepherd never tru...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>I am really flattered and happy to hear those ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text anger anticipation  \\\n",
       "882  @BadHombreNPS @SecretaryPerry If this didn't m...     1            0   \n",
       "883  Excited to watch #stateoforigin tonight! Come ...     0            0   \n",
       "884  Blah blah blah Kyrie, IT, etc. @CJC9BOSS leavi...     1            0   \n",
       "885  #ThingsIveLearned The wise #shepherd never tru...     0            0   \n",
       "886  I am really flattered and happy to hear those ...     0            0   \n",
       "\n",
       "    disgust fear joy love optimism pessimism sadness surprise trust  \n",
       "882       1    0   0    0        0         0       0        0     0  \n",
       "883       0    0   1    0        1         0       0        0     0  \n",
       "884       1    0   0    0        0         0       1        0     0  \n",
       "885       0    0   0    0        0         0       0        0     0  \n",
       "886       0    0   1    0        1         0       0        0     0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SemEval2018\n",
    "se_val = pd.read_csv('../data/raw/SemEval2018/2018-E-c-En-dev.txt', sep='\\t', names=['ID', 'text', 'anger', 'anticipation', 'disgust', 'fear', 'joy',\t'love',\t'optimism', 'pessimism', 'sadness',\t'surprise',\t'trust'])\n",
    "# drop the first row\n",
    "se_val = se_val.drop([0])\n",
    "# drop the ID column\n",
    "se_val = se_val.drop(['ID'], axis=1)\n",
    "\n",
    "se_val.to_csv('../data/clean/SemEval2018_val.csv', index=False)\n",
    "print(\"SemEval2018:\")\n",
    "se_val.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SemEval2018:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Adnan__786__ @AsYouNotWish Dont worry Indian ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Academy of Sciences, eschews the normally sobe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I blew that opportunity -__- #mad</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This time in 2 weeks I will be 30... 😥</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#Deppression is real. Partners w/ #depressed p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text anger anticipation  \\\n",
       "1  @Adnan__786__ @AsYouNotWish Dont worry Indian ...     1            1   \n",
       "2  Academy of Sciences, eschews the normally sobe...     0            0   \n",
       "3                  I blew that opportunity -__- #mad     1            0   \n",
       "4             This time in 2 weeks I will be 30... 😥     0            0   \n",
       "5  #Deppression is real. Partners w/ #depressed p...     0            0   \n",
       "\n",
       "  disgust fear joy love optimism pessimism sadness surprise trust  \n",
       "1       0    0   0    0        1         0       0        0     1  \n",
       "2       1    0   0    0        0         0       0        0     0  \n",
       "3       1    0   0    0        0         0       1        0     0  \n",
       "4       0    0   1    0        0         0       1        0     0  \n",
       "5       0    1   0    0        0         0       1        0     0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SemEval2018\n",
    "se_test = pd.read_csv('../data/raw/SemEval2018/2018-E-c-En-test.txt', sep='\\t', names=['ID', 'text', 'anger', 'anticipation', 'disgust', 'fear', 'joy',\t'love',\t'optimism', 'pessimism', 'sadness',\t'surprise',\t'trust'])\n",
    "# drop the first row\n",
    "se_test = se_test.drop([0])\n",
    "# drop the ID column\n",
    "se_test = se_test.drop(['ID'], axis=1)\n",
    "\n",
    "se_test.to_csv('../data/clean/SemEval2018_test.csv', index=False)\n",
    "print(\"SemEval2018:\")\n",
    "se_test.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify and merge the overlap between the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmoBank + AffectiveText: 1149\n",
      "Repeated rows: 0\n",
      "     id  split     V     A     D  \\\n",
      "0     1  train  2.29  3.29  2.86   \n",
      "1    10  train  3.50  2.88  3.00   \n",
      "2   100  train  2.88  3.00  3.00   \n",
      "3  1000  train  2.00  3.62  2.75   \n",
      "4  1001  train  2.80  3.00  3.00   \n",
      "\n",
      "                                                text  \\\n",
      "0             Mortar assault leaves at least 18 dead   \n",
      "1  Alonso would be happy to retire with three titles   \n",
      "2                Report criticises US press freedoms   \n",
      "3  Terror officials see Al Qaeda chiefs regaining...   \n",
      "4  Ivrea journal: In Italian town, a civics lesso...   \n",
      "\n",
      "                                            instance  anger  disgust  fear  \\\n",
      "0             Mortar assault leaves at least 18 dead     22        2    60   \n",
      "1  Alonso would be happy to retire with three titles      0        0     0   \n",
      "2                Report criticises US press freedoms     25       24     6   \n",
      "3  Terror officials see Al Qaeda chiefs regaining...     13       11    86   \n",
      "4  Ivrea journal: In Italian town, a civics lesso...      0        5     0   \n",
      "\n",
      "   joy  sadness  surprise  \n",
      "0    0       64         0  \n",
      "1   61       24         0  \n",
      "2   21       13        13  \n",
      "3    0       16         3  \n",
      "4    3        0        25  \n"
     ]
    }
   ],
   "source": [
    "# clean up EmoBank ids to match AffectiveText\n",
    "eb['id'] = eb['id'].str.replace('SemEval_', '')\n",
    "at['id'] = at['id'].astype(str)\n",
    "# merge EmoBank and AffectiveText\n",
    "eb_at = pd.merge(eb, at, how='inner', left_on='id', right_on='id',validate='one_to_one')\n",
    "# print number of rows\n",
    "print(\"EmoBank + AffectiveText:\", len(eb_at))\n",
    "# check for repeated rows - should be 0\n",
    "print(\"Repeated rows:\",len(eb_at[eb_at['instance'].duplicated()]))\n",
    "print(eb_at.head())\n",
    "# check for any non-matching examples\n",
    "assert len(eb_at[eb_at['text'] == eb_at['instance']]) == len(eb_at)-1\\\n",
    "    , \"There are non-matching examples\"\n",
    "eb_at = eb_at.drop(columns=['instance'], axis=1)\n",
    "eb_at.to_csv('../data/clean/EmoBank_AffectiveText.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_labels(df, label_cols):\n",
    "    # sum all label values in each row and normalise\n",
    "    df[label_cols] = df[label_cols].div(df[label_cols].sum(axis=1), axis=0)\n",
    "    return df\n",
    "\n",
    "def categorise_labels(df, label_cols):\n",
    "    # 1-hot encode rows with the highest label value\n",
    "    df[label_cols] = df[label_cols].eq(df[label_cols].max(axis=1), axis=0).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise labels\n",
    "eb_at = normalise_labels(eb_at, columns[1:])\n",
    "# 1-hot encode labels\n",
    "eb_at = categorise_labels(eb_at, columns[1:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Children's stories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write full dataset to csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HCAndersen beetle.emmood Error tokenizing data. C error: EOF inside string starting at row 150\n",
      "HCAndersen cock.emmood Error tokenizing data. C error: EOF inside string starting at row 32\n",
      "            author     story annotator_1 annotator_2        sentence\n",
      "count        14024     14024       14024       14024           14024\n",
      "unique           3       174          61          64           13913\n",
      "top     HCAndersen  goloshes         N:N         N:N  Goodbye, Hans.\n",
      "freq          7042       495        8585        5421              11\n",
      "   author                                 story annotator_1 annotator_2  \\\n",
      "0  Grimms  106_the_poor_millers_boy_and_the_cat         N:N         N:N   \n",
      "1  Grimms  106_the_poor_millers_boy_and_the_cat         N:N         N:N   \n",
      "2  Grimms  106_the_poor_millers_boy_and_the_cat         N:D         N:D   \n",
      "3  Grimms  106_the_poor_millers_boy_and_the_cat         N:N         N:D   \n",
      "4  Grimms  106_the_poor_millers_boy_and_the_cat         N:N         N:N   \n",
      "\n",
      "                                            sentence  \n",
      "0  In a certain mill lived an old miller who had ...  \n",
      "1  As they had been with him several years, he on...  \n",
      "2  The third of the boys was, however, the drudge...  \n",
      "3  Then all three went out together, and when the...  \n",
      "4  Hans, however, went with them, and when it was...  \n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../data/raw/children/children' # relative to this notebook\n",
    "authors = ['Grimms', 'HCAndersen', 'Potter']\n",
    "FOLDER = 'emmood'\n",
    "\n",
    "files = os.listdir(os.path.join(DATA_PATH, authors[0], FOLDER))\n",
    "\n",
    "table = pd.DataFrame(columns=['author', 'story', 'annotator_1', 'annotator_2', 'sentence'])\n",
    "for AUTHOR in authors:\n",
    "    for f in os.listdir(os.path.join(DATA_PATH, AUTHOR, 'emmood')):\n",
    "        try:\n",
    "            new_table = pd.read_csv(os.path.join(DATA_PATH, AUTHOR, 'emmood', f), sep='\\t'\\\n",
    "                                    , names=['annotator_1', 'annotator_2', 'sentence']\\\n",
    "                                    , usecols=[1, 2, 3])\n",
    "            new_table['author'] = AUTHOR\n",
    "            new_table['story'] = f.split('.')[0]\n",
    "            table = pd.concat([table, new_table], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(AUTHOR, f, e)\n",
    "            continue\n",
    "print(table.describe())\n",
    "print(table.head())\n",
    "table.to_csv('../data/raw/children.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
